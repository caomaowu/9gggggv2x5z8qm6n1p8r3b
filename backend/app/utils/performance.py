"""
Performance Monitor - æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
é‡æ„åçš„æ€§èƒ½ç›‘æ§æ¨¡å—ï¼Œæ›´æ¸…æ™°å’Œé«˜æ•ˆ
ä½œè€…ï¼šå“ˆé›·é…±ï¼ˆå‚²å¨‡å¤§å°å§å·¥ç¨‹å¸ˆï¼‰
"""

import time
import functools
import logging
from typing import Dict, Any, Optional
from datetime import datetime
from contextlib import contextmanager
import os
import tracemalloc
try:
    import psutil
except Exception:
    psutil = None

logger = logging.getLogger(__name__)


class PerformanceMonitor:
    """
    æ€§èƒ½ç›‘æ§å™¨

    å“¼å“¼ï¼æœ¬å°å§æŠŠæ€§èƒ½ç›‘æ§æ¨¡å—é‡æ„å¾—æ›´ä¼˜é›…äº†ï¼
    """

    def __init__(self):
        """åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨"""
        self.metrics: Dict[str, Any] = {}
        self.stage_stack: list = []
        self.start_time = time.time()
        self.enabled = True
        self._start_resources: Dict[str, Any] = {}
        self._end_resources: Dict[str, Any] = {}
        self._process = psutil.Process(os.getpid()) if psutil else None

    def _snapshot_resources(self) -> Dict[str, Any]:
        data: Dict[str, Any] = {}
        data["process_time"] = time.process_time()
        if self._process:
            try:
                data["cpu_percent"] = self._process.cpu_percent(interval=None)
                mem = self._process.memory_info()
                data["rss"] = getattr(mem, "rss", 0)
                data["vms"] = getattr(mem, "vms", 0)
            except Exception:
                pass
        try:
            if tracemalloc.is_tracing():
                current, peak = tracemalloc.get_traced_memory()
                data["tracemalloc_current"] = current
                data["tracemalloc_peak"] = peak
        except Exception:
            pass
        return data

    def start_monitoring(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        self.start_time = time.time()
        self.metrics.clear()
        self.stage_stack.clear()
        try:
            if not tracemalloc.is_tracing():
                tracemalloc.start()
        except Exception:
            pass
        self._start_resources = self._snapshot_resources()
        logger.info("ğŸ”„ æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")

    def end_monitoring(self) -> Dict[str, Any]:
        """ç»“æŸæ€§èƒ½ç›‘æ§å¹¶ç”ŸæˆæŠ¥å‘Š"""
        if not self.enabled:
            return {}

        total_time = time.time() - self.start_time
        self._end_resources = self._snapshot_resources()
        report = {
            "total_execution_time": total_time,
            "stages": self.metrics.copy(),
            "timestamp": datetime.now().isoformat()
        }
        if self._start_resources or self._end_resources:
            report["resources"] = {
                "start": self._start_resources,
                "end": self._end_resources
            }

        logger.info(f"ğŸ“Š æ€§èƒ½ç›‘æ§ç»“æŸï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        return report

    def record_stage(self, stage_name: str, execution_time: float, additional_data: Dict = None):
        """è®°å½•é˜¶æ®µæ‰§è¡Œæ—¶é—´"""
        if not self.enabled:
            return

        stage_data = {
            "execution_time": execution_time,
            "percentage": 0.0,  # å°†åœ¨ç»“æŸæ—¶è®¡ç®—
            "timestamp": datetime.now().isoformat()
        }

        if additional_data:
            stage_data.update(additional_data)

        self.metrics[stage_name] = stage_data

    def start_stage(self, stage_name: str):
        """å¼€å§‹ä¸€ä¸ªé˜¶æ®µ"""
        if not self.enabled:
            return

        start_time = time.time()
        resource_snapshot = self._snapshot_resources()
        self.stage_stack.append((stage_name, start_time, resource_snapshot))
        # æ”¹ä¸ºDEBUGçº§åˆ«ï¼Œé¿å…å¯åŠ¨æ—¶çš„å™ªéŸ³æ—¥å¿—
        logger.debug(f"ğŸ”„ å¼€å§‹æ‰§è¡Œ: {stage_name}")

    def end_stage(self, stage_name: str = None) -> float:
        """ç»“æŸå½“å‰é˜¶æ®µæˆ–æŒ‡å®šé˜¶æ®µ"""
        if not self.enabled or not self.stage_stack:
            return 0.0

        if stage_name:
            # æŸ¥æ‰¾æŒ‡å®šé˜¶æ®µ
            for i, item in enumerate(self.stage_stack):
                name, start_time, res_start = item
                if name == stage_name:
                    execution_time = time.time() - start_time
                    self.stage_stack.pop(i)
                    res_end = self._snapshot_resources()
                    self.record_stage(stage_name, execution_time, {"resource_start": res_start, "resource_end": res_end})
                    # åªæœ‰æ‰§è¡Œæ—¶é—´å¤§äº0.01ç§’æ—¶æ‰è®°å½•INFOæ—¥å¿—ï¼Œé¿å…å¯¼å…¥æ—¶çš„ç©ºæ‰§è¡Œå™ªéŸ³
                    if execution_time > 0.01:
                        logger.info(f"ğŸ“Š [{stage_name}] å®Œæˆ - è€—æ—¶: {execution_time:.2f}ç§’")
                    return execution_time
        else:
            # ç»“æŸæœ€åé˜¶æ®µ
            name, start_time, res_start = self.stage_stack.pop()
            execution_time = time.time() - start_time
            res_end = self._snapshot_resources()
            self.record_stage(name, execution_time, {"resource_start": res_start, "resource_end": res_end})
            # åªæœ‰æ‰§è¡Œæ—¶é—´å¤§äº0.01ç§’æ—¶æ‰è®°å½•INFOæ—¥å¿—ï¼Œé¿å…å¯¼å…¥æ—¶çš„ç©ºæ‰§è¡Œå™ªéŸ³
            if execution_time > 0.01:
                logger.info(f"ğŸ“Š [{name}] å®Œæˆ - è€—æ—¶: {execution_time:.2f}ç§’")
            return execution_time

        return 0.0

    def calculate_percentages(self, total_time: float):
        """è®¡ç®—å„é˜¶æ®µè€—æ—¶å æ¯”"""
        if total_time <= 0:
            return

        for stage_name, stage_data in self.metrics.items():
            execution_time = stage_data["execution_time"]
            percentage = (execution_time / total_time) * 100
            stage_data["percentage"] = percentage
            logger.info(f"ğŸ“Š [{stage_name}] è€—æ—¶: {execution_time:.2f}ç§’ (å æ¯”: {percentage:.1f}%)")

    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        total_time = sum(stage["execution_time"] for stage in self.metrics.values())
        self.calculate_percentages(total_time)

        return {
            "total_time": total_time,
            "stage_count": len(self.metrics),
            "slowest_stage": max(self.metrics.items(), key=lambda x: x[1]["execution_time"])[0] if self.metrics else None,
            "fastest_stage": min(self.metrics.items(), key=lambda x: x[1]["execution_time"])[0] if self.metrics else None,
            "stages": self.metrics
        }

    def clear_metrics(self):
        """æ¸…ç©ºæ€§èƒ½æŒ‡æ ‡"""
        self.metrics.clear()
        self.stage_stack.clear()
        logger.info("æ€§èƒ½æŒ‡æ ‡å·²æ¸…ç©º")

    def enable(self):
        """å¯ç”¨æ€§èƒ½ç›‘æ§"""
        self.enabled = True
        logger.info("æ€§èƒ½ç›‘æ§å·²å¯ç”¨")

    def disable(self):
        """ç¦ç”¨æ€§èƒ½ç›‘æ§"""
        self.enabled = False
        logger.info("æ€§èƒ½ç›‘æ§å·²ç¦ç”¨")


# å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹
_global_monitor = PerformanceMonitor()


def performance_monitor(stage_name: str = None):
    """
    æ€§èƒ½ç›‘æ§è£…é¥°å™¨

    Args:
        stage_name: é˜¶æ®µåç§°
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            if not _global_monitor.enabled:
                return func(*args, **kwargs)

            name = stage_name or f"{func.__module__}.{func.__name__}"
            _global_monitor.start_stage(name)

            try:
                result = func(*args, **kwargs)
                return result
            finally:
                _global_monitor.end_stage(name)

        return wrapper
    return decorator


@contextmanager
def monitor_context(stage_name: str):
    """
    æ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨

    Args:
        stage_name: é˜¶æ®µåç§°
    """
    if not _global_monitor.enabled:
        yield
        return

    _global_monitor.start_stage(stage_name)
    try:
        yield
    finally:
        _global_monitor.end_stage(stage_name)


def monitor_computation(operation_name: str):
    """
    è®¡ç®—è¿‡ç¨‹ç›‘æ§è£…é¥°å™¨

    Args:
        operation_name: æ“ä½œåç§°
    """
    return performance_monitor(f"è®¡ç®—: {operation_name}")


def monitor_llm_call(model_name: str = None):
    """
    LLMè°ƒç”¨ç›‘æ§è£…é¥°å™¨

    Args:
        model_name: æ¨¡å‹åç§°
    """
    name = f"LLMè°ƒç”¨: {model_name}" if model_name else "LLMè°ƒç”¨"
    return performance_monitor(name)


def monitor_image_generation(chart_type: str = None):
    """
    å›¾åƒç”Ÿæˆç›‘æ§è£…é¥°å™¨

    Args:
        chart_type: å›¾è¡¨ç±»å‹
    """
    name = f"å›¾åƒç”Ÿæˆ: {chart_type}" if chart_type else "å›¾åƒç”Ÿæˆ"
    return performance_monitor(name)


def monitor_api_call(api_name: str = None):
    """
    APIè°ƒç”¨ç›‘æ§è£…é¥°å™¨

    Args:
        api_name: APIåç§°
    """
    name = f"APIè°ƒç”¨: {api_name}" if api_name else "APIè°ƒç”¨"
    return performance_monitor(name)


# å…¨å±€æ§åˆ¶å‡½æ•°
def start_performance_monitoring():
    """å¼€å§‹å…¨å±€æ€§èƒ½ç›‘æ§"""
    _global_monitor.start_monitoring()


def end_performance_monitoring() -> Dict[str, Any]:
    """ç»“æŸå…¨å±€æ€§èƒ½ç›‘æ§"""
    return _global_monitor.end_monitoring()


def get_performance_report() -> Dict[str, Any]:
    """è·å–æ€§èƒ½æŠ¥å‘Š"""
    return _global_monitor.get_summary()


def record_manual_stage(stage_name: str, execution_time: float, **kwargs):
    """æ‰‹åŠ¨è®°å½•é˜¶æ®µ"""
    _global_monitor.record_stage(stage_name, execution_time, kwargs)


def enable_performance_monitoring():
    """å¯ç”¨æ€§èƒ½ç›‘æ§"""
    _global_monitor.enable()


def disable_performance_monitoring():
    """ç¦ç”¨æ€§èƒ½ç›‘æ§"""
    _global_monitor.disable()


def clear_performance_metrics():
    """æ¸…ç©ºæ€§èƒ½æŒ‡æ ‡"""
    _global_monitor.clear_metrics()


# å‘åå…¼å®¹çš„å‡½æ•°
def monitor_stage(stage_name: str):
    """ç›‘æ§é˜¶æ®µï¼ˆå‘åå…¼å®¹ï¼‰"""
    return monitor_context(stage_name)


def record_stage_time(stage_name: str, execution_time: float):
    """è®°å½•é˜¶æ®µæ—¶é—´ï¼ˆå‘åå…¼å®¹ï¼‰"""
    record_manual_stage(stage_name, execution_time)