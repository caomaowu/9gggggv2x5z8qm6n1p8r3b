"""
åŒæ¨¡å‹å†³ç­–æ™ºèƒ½ä½“
å“ˆé›·é…±çš„AIæ¨¡å‹å¯¹æˆ˜ç³»ç»Ÿï¼(ï¿£â–½ï¿£)ï¼

è¿™ä¸ªæ¨¡å—å®ç°äº†åŒæ¨¡å‹å¹¶è¡Œå†³ç­–åŠŸèƒ½ï¼Œ
æ”¯æŒä¸¤ä¸ªä¸åŒçš„AIæ¨¡å‹åŒæ—¶è¿›è¡Œåˆ†æï¼Œå¹¶æä¾›å¯¹æ¯”ç»“æœã€‚
"""

import asyncio
import json
import time
from datetime import datetime
from typing import Dict, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass

# å“ˆé›·é…±çš„æ¨¡å—åŒ–å¯¼å…¥ï¼
import sys
from pathlib import Path
# sys.path hack removed

from app.agents.decision_agent_factory import get_decision_agent_factory
from app.agents.decision_configs import risk_control
from app.core.dual_model_config import get_dual_model_config_manager
from app.utils.performance import performance_monitor


@dataclass
class ModelResult:
    """æ¨¡å‹åˆ†æç»“æœ"""
    model_id: str
    model_name: str
    decision: str
    confidence: float
    reasoning: str
    risk_reward: str
    time_horizon: str
    execution_time: float
    error: Optional[str] = None
    timestamp: str = None
    # å“ˆé›·é…±ï¼šæ·»åŠ æ­¢ç›ˆæ­¢æŸå’Œå¸‚åœºç¯å¢ƒå­—æ®µ
    stop_loss: Optional[float] = None
    take_profit: Optional[float] = None
    stop_loss_adj: Optional[float] = None
    take_profit_adj: Optional[float] = None
    market_environment: Optional[str] = None
    volatility_assessment: Optional[str] = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()


@dataclass
class DualModelAnalysisResult:
    """åŒæ¨¡å‹åˆ†æç»“æœ"""
    model_1_result: ModelResult
    model_2_result: Optional[ModelResult]
    comparison: Dict[str, Any]
    total_execution_time: float

    @property
    def is_dual_mode(self) -> bool:
        """æ˜¯å¦ä¸ºåŒæ¨¡å‹æ¨¡å¼"""
        return self.model_2_result is not None

    @property
    def has_consensus(self) -> bool:
        """ä¸¤ä¸ªæ¨¡å‹æ˜¯å¦è¾¾æˆä¸€è‡´"""
        if not self.is_dual_mode:
            return True
        return self.model_1_result.decision == self.model_2_result.decision

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œæ”¯æŒJSONåºåˆ—åŒ– - å“ˆé›·é…±çš„ä¿®å¤ï¼"""
        result = {
            "model_1_result": {
                "model_id": self.model_1_result.model_id,
                "model_name": self.model_1_result.model_name,
                "decision": self.model_1_result.decision,
                "confidence": self.model_1_result.confidence,
                "reasoning": self.model_1_result.reasoning,
                "risk_reward": self.model_1_result.risk_reward,
                "time_horizon": self.model_1_result.time_horizon,
                "execution_time": self.model_1_result.execution_time,
                "error": self.model_1_result.error,
                "timestamp": self.model_1_result.timestamp,
                # å“ˆé›·é…±ï¼šæ·»åŠ æ­¢ç›ˆæ­¢æŸå’Œå¸‚åœºç¯å¢ƒå­—æ®µï¼
                "stop_loss": self.model_1_result.stop_loss,
                "take_profit": self.model_1_result.take_profit,
                "stop_loss_adj": self.model_1_result.stop_loss_adj,
                "take_profit_adj": self.model_1_result.take_profit_adj,
                "market_environment": self.model_1_result.market_environment,
                "volatility_assessment": self.model_1_result.volatility_assessment
            },
            "comparison": self.comparison,
            "total_execution_time": self.total_execution_time,
            "is_dual_mode": self.is_dual_mode,
            "has_consensus": self.has_consensus
        }

        # æ·»åŠ æ¨¡å‹2ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.model_2_result:
            result["model_2_result"] = {
                "model_id": self.model_2_result.model_id,
                "model_name": self.model_2_result.model_name,
                "decision": self.model_2_result.decision,
                "confidence": self.model_2_result.confidence,
                "reasoning": self.model_2_result.reasoning,
                "risk_reward": self.model_2_result.risk_reward,
                "time_horizon": self.model_2_result.time_horizon,
                "execution_time": self.model_2_result.execution_time,
                "error": self.model_2_result.error,
                "timestamp": self.model_2_result.timestamp,
                # å“ˆé›·é…±ï¼šæ·»åŠ æ­¢ç›ˆæ­¢æŸå’Œå¸‚åœºç¯å¢ƒå­—æ®µï¼
                "stop_loss": self.model_2_result.stop_loss,
                "take_profit": self.model_2_result.take_profit,
                "stop_loss_adj": self.model_2_result.stop_loss_adj,
                "take_profit_adj": self.model_2_result.take_profit_adj,
                "market_environment": self.model_2_result.market_environment,
                "volatility_assessment": self.model_2_result.volatility_assessment
            }

        return result


class DualModelDecisionAgent:
    """åŒæ¨¡å‹å†³ç­–æ™ºèƒ½ä½“"""

    def __init__(self):
        """åˆå§‹åŒ–åŒæ¨¡å‹å†³ç­–æ™ºèƒ½ä½“"""
        self.factory = get_decision_agent_factory()
        self.config_manager = get_dual_model_config_manager()
        self.executor = ThreadPoolExecutor(max_workers=2)

    def analyze_with_dual_models(self, state: Dict[str, Any]) -> DualModelAnalysisResult:
        """
        ä½¿ç”¨åŒæ¨¡å‹è¿›è¡Œåˆ†æ

        Args:
            state: åˆ†æçŠ¶æ€æ•°æ®

        Returns:
            DualModelAnalysisResult: åŒæ¨¡å‹åˆ†æç»“æœ
        """
        start_time = time.time()

        # å“ˆé›·é…±å¢å¼ºï¼šè¾“å‡ºå¯åŠ¨ä¿¡æ¯ï¼
        stock_name = state.get("stock_name", state.get("display_name", "æœªçŸ¥"))
        timeframe = state.get("timeframe", "æœªçŸ¥")
        print(f"ğŸš€ [åŒæ¨¡å‹å†³ç­–ç³»ç»Ÿ] å¼€å§‹åˆ†æ: {stock_name} ({timeframe})")

        # è·å–é…ç½®
        dual_config = self.config_manager.get_dual_model_config()
        is_enabled = dual_config.get("enabled", False)

        print(f"âš™ï¸  [åŒæ¨¡å‹é…ç½®] åŒæ¨¡å‹æ¨¡å¼: {'å¯ç”¨' if is_enabled else 'ç¦ç”¨'}")

        if not is_enabled:
            # å•æ¨¡å‹æ¨¡å¼
            print("ğŸ“Š [åŒæ¨¡å‹å†³ç­–ç³»ç»Ÿ] æ‰§è¡Œå•æ¨¡å‹åˆ†æ...")
            return self._analyze_single_model(state, start_time)
        else:
            # åŒæ¨¡å‹æ¨¡å¼
            model_1 = dual_config.get("model_1", "æœªçŸ¥")
            model_2 = dual_config.get("model_2", "æœªçŸ¥")
            print(f"ğŸ”„ [åŒæ¨¡å‹å†³ç­–ç³»ç»Ÿ] æ‰§è¡ŒåŒæ¨¡å‹å¯¹æ¯”åˆ†æ:")
            print(f"   æ¨¡å‹A: {model_1}")
            print(f"   æ¨¡å‹B: {model_2}")
            return self._analyze_dual_models(state, dual_config, start_time)

    def _analyze_single_model(self, state: Dict[str, Any], start_time: float) -> DualModelAnalysisResult:
        """å•æ¨¡å‹åˆ†æ"""
        try:
            # å“ˆé›·é…±ï¼šç›´æ¥åˆ›å»ºLLMå¯¹è±¡ï¼Œé¿å…é…ç½®é—®é¢˜ï¼
            from app.core.config import config
            from langchain_openai import ChatOpenAI

            # åˆ›å»ºLLMå¯¹è±¡
            llm = ChatOpenAI(
                model=config.llm.agent_model,
                temperature=config.llm.agent_temperature,
                api_key=config.llm.api_key,
                base_url=config.llm.base_url
            )

            print(f"[å•æ¨¡å‹åˆ†æ] åˆ›å»ºLLM: {config.llm.agent_model}")

            # åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆå°Šé‡çŠ¶æ€ä¸­çš„ç‰ˆæœ¬é€‰æ‹©ï¼Œé»˜è®¤constrainedï¼‰
            version = state.get("decision_agent_version", "constrained")
            agent = self.factory.create_agent(version, llm)

            # æ‰§è¡Œåˆ†æ
            result = agent(state)

            # è§£æç»“æœ
            model_result = self._parse_model_result(result, config.llm.agent_model, "ä¸»æ¨¡å‹", state)

            # åˆ›å»ºå¯¹æ¯”ç»“æœ
            comparison = {
                "mode": "single",
                "model_count": 1,
                "consensus": True,
                "message": "å•æ¨¡å‹åˆ†ææ¨¡å¼"
            }

            execution_time = time.time() - start_time

            return DualModelAnalysisResult(
                model_1_result=model_result,
                model_2_result=None,
                comparison=comparison,
                total_execution_time=execution_time
            )

        except Exception as e:
            print(f"[å•æ¨¡å‹åˆ†æ] åˆ†æå¤±è´¥: {e}")

            # é”™è¯¯å¤„ç†
            model_result = ModelResult(
                model_id="ä¸»æ¨¡å‹",
                model_name="ä¸»æ¨¡å‹",
                decision="é”™è¯¯",
                confidence=0.0,
                reasoning=f"åˆ†æå¤±è´¥: {str(e)}",
                risk_reward="N/A",
                time_horizon="N/A",
                execution_time=time.time() - start_time,
                error=str(e)
            )

            comparison = {
                "mode": "single",
                "model_count": 1,
                "consensus": False,
                "message": "åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯"
            }

            return DualModelAnalysisResult(
                model_1_result=model_result,
                model_2_result=None,
                comparison=comparison,
                total_execution_time=time.time() - start_time
            )

    def _analyze_dual_models(self, state: Dict[str, Any], dual_config: Dict[str, Any], start_time: float) -> DualModelAnalysisResult:
        """åŒæ¨¡å‹å¹¶è¡Œåˆ†æ"""
        model_1_config = {
            "model": dual_config.get("model_1", ""),
            "temperature": dual_config.get("temperature_1", 0.1)
        }
        model_2_config = {
            "model": dual_config.get("model_2", ""),
            "temperature": dual_config.get("temperature_2", 0.1)
        }

        # å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªæ¨¡å‹çš„åˆ†æ
        future_1 = self.executor.submit(self._analyze_single_model_async, state, model_1_config, "æ¨¡å‹A")

        # 2ç§’å»¶è¿Ÿå¯åŠ¨ç¬¬äºŒä¸ªæ¨¡å‹ï¼Œé¿å…APIé™é€Ÿ
        time.sleep(2)
        future_2 = self.executor.submit(self._analyze_single_model_async, state, model_2_config, "æ¨¡å‹B")

        # ç­‰å¾…ç»“æœ
        model_1_result = future_1.result()
        model_2_result = future_2.result()

        # ç”Ÿæˆå¯¹æ¯”åˆ†æ
        comparison = self._generate_comparison(model_1_result, model_2_result)

        total_execution_time = time.time() - start_time

        return DualModelAnalysisResult(
            model_1_result=model_1_result,
            model_2_result=model_2_result,
            comparison=comparison,
            total_execution_time=total_execution_time
        )

    def _analyze_single_model_async(self, state: Dict[str, Any], model_config: Dict[str, Any], model_name: str) -> ModelResult:
        """å¼‚æ­¥æ‰§è¡Œå•ä¸ªæ¨¡å‹åˆ†æ"""
        start_time = time.time()

        try:
            # å“ˆé›·é…±å¢å¼ºï¼šçŠ¶æ€æ•°æ®å®Œæ•´æ€§éªŒè¯ï¼
            self._validate_state_data(state, model_name)

            # å“ˆé›·é…±ï¼šç›´æ¥åˆ›å»ºæ–°çš„LLMå¯¹è±¡å’Œæ™ºèƒ½ä½“ï¼Œé¿å…é…ç½®é—®é¢˜ï¼
            from app.core.config import config
            from langchain_openai import ChatOpenAI

            # åˆ›å»ºæ–°çš„LLMå¯¹è±¡
            llm = ChatOpenAI(
                model=model_config.get("model", config.llm.agent_model),
                temperature=model_config.get("temperature", 0.1),
                api_key=config.llm.api_key,
                base_url=config.llm.base_url
            )

            print(f"[åŒæ¨¡å‹åˆ†æ] åˆ›å»ºLLM: {model_config.get('model')}")

            # ä½¿ç”¨å·¥å‚æŒ‰ç‰ˆæœ¬åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆæ¥è‡ªçŠ¶æ€ï¼‰
            version = state.get("decision_agent_version", "constrained")
            agent = self.factory.create_agent(version, llm)

            # æ‰§è¡Œåˆ†æ
            print(f"[{model_name}] ğŸ§  å¼€å§‹æ‰§è¡ŒAIå†³ç­–åˆ†æ...")
            result = agent(state)
            print(f"[{model_name}] âœ… AIåˆ†æå®Œæˆï¼Œå¼€å§‹è§£æç»“æœ...")

            # å“ˆé›·é…±ä¿®å¤ï¼šä»å†³ç­–æ™ºèƒ½ä½“ç»“æœä¸­æå–final_trade_decision
            if "final_trade_decision" in result:
                decision_json = result["final_trade_decision"]
                print(f"[{model_name}] ğŸ“‹ æå–åˆ°å†³ç­–JSON: {decision_json[:100]}...")
                model_result = self._parse_model_result(decision_json, model_config["model"], model_name, state)
            else:
                print(f"[{model_name}] âš ï¸  æœªæ‰¾åˆ°final_trade_decisionå­—æ®µï¼Œä½¿ç”¨å®Œæ•´ç»“æœ")
                model_result = self._parse_model_result(result, model_config["model"], model_name, state)

            model_result.execution_time = time.time() - start_time

            # å“ˆé›·é…±å¢å¼ºï¼šè¾“å‡ºå…³é”®ç»“æœä¿¡æ¯ï¼
            print(f"[{model_name}] ğŸ¯ å†³ç­–ç»“æœ: {model_result.decision}")
            print(f"[{model_name}] ğŸ“Š ç½®ä¿¡åº¦: {model_result.confidence:.2f}")
            print(f"[{model_name}] â±ï¸  æ‰§è¡Œæ—¶é—´: {model_result.execution_time:.2f}ç§’")

            return model_result

        except Exception as e:
            print(f"[åŒæ¨¡å‹åˆ†æ] {model_name} åˆ†æå¤±è´¥: {e}")

            return ModelResult(
                model_id=model_config.get("model", "Unknown"),
                model_name=model_name,
                decision="é”™è¯¯",
                confidence=0.0,
                reasoning=f"åˆ†æå¤±è´¥: {str(e)}",
                risk_reward="N/A",
                time_horizon="N/A",
                execution_time=time.time() - start_time,
                error=str(e)
            )

    def _parse_model_result(self, result: Dict[str, Any], model_id: str, model_name: str, state: Dict[str, Any]) -> ModelResult:
        """è§£ææ¨¡å‹ç»“æœ"""
        if "error" in result:
            return ModelResult(
                model_id=model_id,
                model_name=model_name,
                decision="é”™è¯¯",
                confidence=0.0,
                reasoning=result["error"],
                risk_reward="N/A",
                time_horizon="N/A",
                error=result["error"]
            )

        # å“ˆé›·é…±ä¿®å¤ï¼šè§£æJSONå­—ç¬¦ä¸²æ ¼å¼å’Œå­—å…¸æ ¼å¼ï¼
        if isinstance(result, str):
            # å¦‚æœæ˜¯JSONå­—ç¬¦ä¸²ï¼Œå…ˆè§£æ
            try:
                import json
                result = json.loads(result)
                print(f"[{model_name}] ğŸ“„ JSONè§£ææˆåŠŸï¼Œå­—æ®µæ•°: {len(result)}")
            except Exception as e:
                print(f"[{model_name}] âš ï¸  JSONè§£æå¤±è´¥: {e}")
                print(f"[{model_name}] åŸå§‹æ•°æ®: {result[:200]}...")
                return ModelResult(
                    model_id=model_id,
                    model_name=model_name,
                    decision="è§£æé”™è¯¯",
                    confidence=0.0,
                    reasoning=f"JSONè§£æå¤±è´¥: {str(e)}",
                    risk_reward="N/A",
                    time_horizon="N/A",
                    error="JSONè§£æå¤±è´¥"
                )

        # æå–å†³ç­–ä¿¡æ¯ - æ”¯æŒå¤šç§å­—æ®µå
        decision = result.get("decision", result.get("final_trade_decision", "æœªçŸ¥"))

        # ç½®ä¿¡åº¦ï¼šæ”¯æŒå¤šç§æ ¼å¼
        confidence_str = result.get("confidence_level", result.get("confidence", "0"))
        try:
            if isinstance(confidence_str, str) and '%' in confidence_str:
                confidence = float(confidence_str.replace('%', '')) / 100
            elif confidence_str in ["ä½", "ä¸­", "é«˜"]:
                confidence_map = {"ä½": 0.3, "ä¸­": 0.6, "é«˜": 0.8}
                confidence = confidence_map.get(confidence_str, 0.0)
            else:
                confidence = float(confidence_str)
        except Exception as e:
            print(f"[{model_name}] âš ï¸  ç½®ä¿¡åº¦è§£æå¤±è´¥: {e}, åŸå€¼: {confidence_str}")
            confidence = 0.0

        reasoning = result.get("justification", result.get("reasoning", "æ— æ¨ç†è¯´æ˜"))

        risk_reward_ratio = result.get("risk_reward_ratio", result.get("risk_reward", "N/A"))
        risk_reward = "N/A"

        time_horizon = result.get("forecast_horizon", result.get("time_horizon", "N/A"))

        # å“ˆé›·é…±ä¿®å¤ï¼šæå–æ­¢ç›ˆæ­¢æŸä»·æ ¼ï¼
        stop_loss = result.get("stop_loss", None)
        take_profit = result.get("take_profit", None)
        market_environment = result.get("market_environment", "æœªçŸ¥")
        volatility_assessment = result.get("volatility_assessment", "æœªçŸ¥")

        print(f"[{model_name}] âœ… è§£æå®Œæˆ:")
        print(f"[{model_name}]    - å†³ç­–: {decision}")
        print(f"[{model_name}]    - ç½®ä¿¡åº¦: {confidence:.2f} (åŸå§‹: {confidence_str})")
        print(f"[{model_name}]    - é£é™©å›æŠ¥æ¯”: {risk_reward}")
        print(f"[{model_name}]    - æ—¶é—´æ¡†æ¶: {time_horizon}")
        print(f"[{model_name}]    - å¸‚åœºç¯å¢ƒ: {market_environment}")
        print(f"[{model_name}]    - æ³¢åŠ¨æ€§: {volatility_assessment}")
        print(f"[{model_name}]    - æ­¢æŸä»·æ ¼: {stop_loss}")
        print(f"[{model_name}]    - æ­¢ç›ˆä»·æ ¼: {take_profit}")
        print(f"[{model_name}]    - æ¨ç†é•¿åº¦: {len(str(reasoning))} å­—ç¬¦")

        # åˆ›å»ºæ‰©å±•çš„ç»“æœå­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰å­—æ®µ
        extended_result = {
            "decision": decision,
            "confidence": confidence,
            "reasoning": reasoning,
            "risk_reward": risk_reward,
            "time_horizon": time_horizon,
            "market_environment": market_environment,
            "volatility_assessment": volatility_assessment,
            "stop_loss": stop_loss,
            "take_profit": take_profit,
            "raw_data": result  # ä¿å­˜åŸå§‹æ•°æ®ä¾›æ¨¡æ¿ä½¿ç”¨
        }

        entry_price = state.get("latest_price")
        if state.get("decision_agent_version") == "comprehensive":
            return ModelResult(
                model_id=model_id,
                model_name=model_name,
                decision=decision,
                confidence=confidence,
                reasoning=reasoning,
                risk_reward="N/A",
                time_horizon=time_horizon,
                execution_time=0.0,
                stop_loss=stop_loss,
                take_profit=take_profit,
                stop_loss_adj=None,
                take_profit_adj=None,
                market_environment=market_environment,
                volatility_assessment=volatility_assessment
            )
        decision_txt = str(decision).lower()
        direction = "long" if ("long" in decision_txt or "åšå¤š" in decision_txt) else ("short" if ("short" in decision_txt or "åšç©º" in decision_txt) else "hold")
        rr_value = result.get("risk_reward_ratio")
        try:
            rr_value = float(rr_value) if rr_value is not None else None
        except:
            rr_value = None
        rr_lo = float(risk_control.get("rr_lo", 1.3))
        rr_hi = float(risk_control.get("rr_hi", 1.8))
        rr_target = rr_value if rr_value is not None else (rr_lo + rr_hi) / 2.0
        if rr_target < rr_lo:
            rr_target = rr_lo
        if rr_target > rr_hi:
            rr_target = rr_hi
        floor_pct = float(risk_control.get("floor_pct", 0.003))
        vol_floor_map = risk_control.get("vol_floor_map", {})
        vol_floor = float(vol_floor_map.get(volatility_assessment, 0.0)) if isinstance(vol_floor_map, dict) else 0.0
        min_sl_pct = floor_pct if floor_pct > vol_floor else vol_floor
        stop_loss_adj = None
        take_profit_adj = None
        def _to_float(x):
            try:
                return float(x)
            except:
                return None
        slf = _to_float(stop_loss)
        tpf = _to_float(take_profit)
        computed_rr = None
        if entry_price is not None and isinstance(entry_price, (int, float)):
            if slf is not None and tpf is not None:
                try:
                    computed_rr = abs(tpf - entry_price) / abs(entry_price - slf)
                except:
                    computed_rr = None
            if direction == "short":
                loss_pct = None
                if slf is not None:
                    loss_pct = (slf - entry_price) / entry_price
                if slf is None or (loss_pct is not None and loss_pct < min_sl_pct):
                    stop_loss_adj = entry_price * (1.0 + min_sl_pct)
                    loss_pct = min_sl_pct
                if tpf is None or (computed_rr is not None and computed_rr < rr_target):
                    if loss_pct is None and slf is not None:
                        loss_pct = abs(entry_price - slf) / entry_price
                    if loss_pct is not None:
                        take_profit_adj = entry_price * (1.0 - rr_target * loss_pct)
            elif direction == "long":
                loss_pct = None
                if slf is not None:
                    loss_pct = (entry_price - slf) / entry_price
                if slf is None or (loss_pct is not None and loss_pct < min_sl_pct):
                    stop_loss_adj = entry_price * (1.0 - min_sl_pct)
                    loss_pct = min_sl_pct
                if tpf is None or (computed_rr is not None and computed_rr < rr_target):
                    if loss_pct is None and slf is not None:
                        loss_pct = abs(entry_price - slf) / entry_price
                    if loss_pct is not None:
                        take_profit_adj = entry_price * (1.0 + rr_target * loss_pct)

        if computed_rr is not None:
            try:
                risk_reward = f"1:{round(computed_rr, 2)}"
            except:
                risk_reward = "N/A"

        print(f"[{model_name}]    - æ ¡æ­£åæ­¢æŸ: {stop_loss_adj}")
        print(f"[{model_name}]    - æ ¡æ­£åæ­¢ç›ˆ: {take_profit_adj}")

        eff_sl = stop_loss_adj if stop_loss_adj is not None else slf
        eff_tp = take_profit_adj if take_profit_adj is not None else tpf
        rr_display = "N/A"
        if entry_price is not None and isinstance(entry_price, (int, float)) and eff_sl is not None and eff_tp is not None:
            try:
                rr_effective = abs(eff_tp - entry_price) / abs(entry_price - eff_sl)
                rr_display = f"1:{round(rr_effective, 2)}"
            except:
                rr_display = risk_reward

        return ModelResult(
            model_id=model_id,
            model_name=model_name,
            decision=decision,
            confidence=confidence,
            reasoning=reasoning,
            risk_reward=rr_display,
            time_horizon=time_horizon,
            execution_time=0.0,
            stop_loss=stop_loss,
            take_profit=take_profit,
            stop_loss_adj=stop_loss_adj,
            take_profit_adj=take_profit_adj,
            market_environment=market_environment,
            volatility_assessment=volatility_assessment
        )

    def _generate_comparison(self, result_1: ModelResult, result_2: ModelResult) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡å‹å¯¹æ¯”åˆ†æ"""
        comparison = {
            "mode": "dual",
            "model_count": 2,
            "consensus": result_1.decision == result_2.decision,
            "model_1": {
                "name": result_1.model_name,
                "decision": result_1.decision,
                "confidence": result_1.confidence,
                "color": "#3B82F6"  # è“è‰²
            },
            "model_2": {
                "name": result_2.model_name,
                "decision": result_2.decision,
                "confidence": result_2.confidence,
                "color": "#F97316"  # æ©™è‰²
            },
            "differences": [],
            "summary": ""
        }

        # åˆ†æå·®å¼‚
        if result_1.decision != result_2.decision:
            comparison["differences"].append({
                "type": "å†³ç­–åˆ†æ­§",
                "description": f"æ¨¡å‹Aå»ºè®®{result_1.decision}ï¼Œæ¨¡å‹Bå»ºè®®{result_2.decision}"
            })

        confidence_diff = abs(result_1.confidence - result_2.confidence)
        if confidence_diff > 0.2:
            comparison["differences"].append({
                "type": "ç½®ä¿¡åº¦å·®å¼‚",
                "description": f"ç½®ä¿¡åº¦å·®å¼‚è¾ƒå¤§ï¼š{confidence_diff:.2f}"
            })

        # ç”Ÿæˆæ€»ç»“
        if comparison["consensus"]:
            comparison["summary"] = f"ä¸¤ä¸ªæ¨¡å‹è¾¾æˆä¸€è‡´ï¼Œéƒ½å»ºè®®{result_1.decision}"
        else:
            comparison["summary"] = f"æ¨¡å‹å­˜åœ¨åˆ†æ­§ï¼Œè¯·è°¨æ…å†³ç­–"

        return comparison

    def _get_current_llm_config(self) -> Dict[str, Any]:
        """è·å–å½“å‰LLMé…ç½®"""
        # è¿™é‡Œéœ€è¦ä»å®é™…çš„é…ç½®ç³»ç»Ÿä¸­è·å–
        # æš‚æ—¶è¿”å›ç©ºå­—å…¸ï¼Œå…·ä½“å®ç°å–å†³äºé…ç½®ç³»ç»Ÿçš„ç»“æ„
        return {}

    def _update_llm_config(self, model_config: Dict[str, Any]) -> None:
        """æ›´æ–°LLMé…ç½® - å“ˆé›·é…±çš„å®ç°ï¼"""
        try:
            from app.core.config import config
            from langchain_openai import ChatOpenAI

            # ä¿å­˜åŸå§‹é…ç½®
            if not hasattr(self, '_original_llm'):
                self._original_llm = {
                    'model': config.llm.agent_model,
                    'temperature': config.llm.agent_temperature
                }

            # æ›´æ–°é…ç½®
            config.llm.agent_model = model_config.get("model", config.llm.agent_model)
            config.llm.agent_temperature = model_config.get("temperature", config.llm.agent_temperature)

            print(f"[åŒæ¨¡å‹é…ç½®] æ›´æ–°LLMé…ç½®: {config.llm.agent_model}")

        except Exception as e:
            print(f"[åŒæ¨¡å‹é…ç½®] æ›´æ–°LLMé…ç½®å¤±è´¥: {e}")

    def _restore_llm_config(self, original_config: Dict[str, Any]) -> None:
        """æ¢å¤LLMé…ç½® - å“ˆé›·é…±çš„å®ç°ï¼"""
        try:
            from app.core.config import config

            # æ¢å¤åŸå§‹é…ç½®
            if hasattr(self, '_original_llm'):
                config.llm.agent_model = self._original_llm['model']
                config.llm.agent_temperature = self._original_llm['temperature']
                print(f"[åŒæ¨¡å‹é…ç½®] æ¢å¤LLMé…ç½®: {config.llm.agent_model}")

        except Exception as e:
            print(f"[åŒæ¨¡å‹é…ç½®] æ¢å¤LLMé…ç½®å¤±è´¥: {e}")

    def _validate_state_data(self, state: Dict[str, Any], model_name: str) -> None:
        """å“ˆé›·é…±å¢å¼ºï¼šéªŒè¯çŠ¶æ€æ•°æ®çš„å®Œæ•´æ€§ï¼"""
        print(f"[{model_name}] ğŸ” å¼€å§‹éªŒè¯çŠ¶æ€æ•°æ®å®Œæ•´æ€§...")
        print(f"[{model_name}] ğŸ“‹ æ”¶åˆ°çš„çŠ¶æ€å­—æ®µ: {list(state.keys())}")

        # æ£€æŸ¥å¿…éœ€çš„å­—æ®µ
        required_fields = {
            "indicator_report": "æŠ€æœ¯æŒ‡æ ‡åˆ†æ",
            "pattern_report": "å½¢æ€åˆ†æ",
            "trend_report": "è¶‹åŠ¿åˆ†æ"
        }

        missing_fields = []
        available_fields = []

        for field, description in required_fields.items():
            value = state.get(field, "")
            print(f"[{model_name}] ğŸ” æ£€æŸ¥å­—æ®µ {field}: {repr(str(value)[:50])}")

            if not value or value == f"{description}ä¸å¯ç”¨" or value == f"{description}å¤±è´¥":
                missing_fields.append(f"{field} ({description})")
            else:
                available_fields.append(f"{field} ({description})")

        # æ£€æŸ¥ä»·æ ¼ä¿¡æ¯
        latest_price = state.get("latest_price")
        price_info = state.get("price_info", "")

        print(f"[{model_name}] ğŸ’° ä»·æ ¼ä¿¡æ¯æ£€æŸ¥: latest_price={latest_price}, price_info={repr(str(price_info)[:30])}")

        if latest_price is None:
            missing_fields.append("latest_price (æœ€æ–°ä»·æ ¼)")
        else:
            available_fields.append(f"latest_price (ä»·æ ¼: {latest_price})")

        if not price_info:
            missing_fields.append("price_info (ä»·æ ¼ä¿¡æ¯)")
        else:
            available_fields.append(f"price_info (ä»·æ ¼è¯¦æƒ…)")

        # è¾“å‡ºéªŒè¯ç»“æœ
        if missing_fields:
            print(f"[{model_name}] âš ï¸  ç¼ºå¤±å­—æ®µ: {', '.join(missing_fields)}")
        else:
            print(f"[{model_name}] âœ… æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å¯ç”¨")

        if available_fields:
            print(f"[{model_name}] ğŸ“Š å¯ç”¨å­—æ®µ: {', '.join(available_fields)}")

        # æ£€æŸ¥åŸºç¡€å­—æ®µ
        stock_name = state.get("stock_name", state.get("display_name", "æœªçŸ¥"))
        timeframe = state.get("timeframe", "æœªçŸ¥")
        print(f"[{model_name}] ğŸ¯ åˆ†æç›®æ ‡: {stock_name} ({timeframe})")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=False)


# å…¨å±€åŒæ¨¡å‹æ™ºèƒ½ä½“å®ä¾‹
_dual_agent_instance = None


def get_dual_model_decision_agent() -> DualModelDecisionAgent:
    """è·å–å…¨å±€åŒæ¨¡å‹å†³ç­–æ™ºèƒ½ä½“å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _dual_agent_instance
    if _dual_agent_instance is None:
        _dual_agent_instance = DualModelDecisionAgent()
    return _dual_agent_instance


@performance_monitor("åŒæ¨¡å‹å†³ç­–åˆ†æ")
def analyze_with_dual_models(state: Dict[str, Any]) -> DualModelAnalysisResult:
    """ä¾¿æ·å‡½æ•°ï¼šä½¿ç”¨åŒæ¨¡å‹è¿›è¡Œåˆ†æ"""
    agent = get_dual_model_decision_agent()
    return agent.analyze_with_dual_models(state)


def create_dual_model_decision_node():
    """åˆ›å»ºåŒæ¨¡å‹å†³ç­–èŠ‚ç‚¹"""
    def dual_model_decision_node(state: Dict[str, Any]) -> Dict[str, Any]:
        """åŒæ¨¡å‹å†³ç­–èŠ‚ç‚¹æ‰§è¡Œå‡½æ•°"""
        print("[åŒæ¨¡å‹å†³ç­–] å¼€å§‹åŒæ¨¡å‹åˆ†æ...")

        # æ‰§è¡ŒåŒæ¨¡å‹åˆ†æ
        result = analyze_with_dual_models(state)

        # å‡†å¤‡è¿”å›æ•°æ®
        return_data = {
            "messages": state.get("messages", []),
            "dual_model_analysis": result,
            "model_1_report": result.model_1_result.reasoning,
            "model_2_report": result.model_2_result.reasoning if result.is_dual_mode else "",
            "model_comparison": result.comparison,
            "analysis_time": datetime.now().isoformat()
        }

        print(f"[åŒæ¨¡å‹å†³ç­–] åˆ†æå®Œæˆï¼Œæ¨¡å¼ï¼š{'åŒæ¨¡å‹' if result.is_dual_mode else 'å•æ¨¡å‹'}")
        print(f"[åŒæ¨¡å‹å†³ç­–] æ€»è€—æ—¶ï¼š{result.total_execution_time:.2f}ç§’")

        return return_data

    return dual_model_decision_node